# Chapter 6: Text Processing & Editing

# What are 'filter programs'? TODO
(take from Ahmad's) This should be in the pipeline chapter


## Viewing Text Files
**cat** â€” Concatenate and print files

`cat /etc/os-release`<br>
Use: Print the contents of a file.


**less** â€” View files page by page<br>
`less /var/log/syslog` <br>
Use `q` to quit<br>
Use `/` to search inside the file

**head** & **tail** â€” View the start/end of a file <br>
`head -n 10 /etc/passwd`

`tail -n 10 /etc/passwd`

### ðŸ’» Exercise  -- view file contents

View the file `/etc/passwd` using `less`

search for the word `root`

Display the last 5 lines of the file using `tail`


## Searching Within Files
`grep` - Search using regular expressions <br>
`grep root /etc/passwd` <br>
`egrep` - Same as grep -E (extended regex)
`egrep '^(daemon|sys)' /etc/passwd` <br>


### ðŸ’» Exercise -- searching within files
- Search for your current username in /etc/passwd:

`whoami`  <br>
`grep $(whoami) /etc/passwd`


- Find lines that start with `nobody` or `daemon` using egrep. To do this you need to use regex [(regualr expression)](../regex/regex.md)


<br><br>
To count characters/words/lines use `wc` (you guessed it: Word Count!)

### ðŸ’» Exercise -- count lines

how many lines in /etc/passwd?

answer: `wc -l /etc/passwd`


## Sorting and filtering
Use `sort` to do all kinds of sorting. You can choose by which keys. 

Use `uniq` to remove duplicate lines (if they are next to each other)

## cutting some columns
Just use `cut` to remove (or select) characters or fields based on their position. This command is especially handy to process strctured data such as CSV and log files)

The command can extract characters or bytes or fields

The examples will make it clear:
```
echo "abcdefgh" | cut -c 1-4    â†’ `abcd`
echo "abcdefgh" | cut -c 2      â†’ `b`
echo "abcdefgh" | cut -c 2-     â†’ `bcdefgh`
```

Cut by field (a field is a string separated by some character such as space):

we have this CSV file:
```
name,age,city
John,25,London
```
and we want to get fields 1 and 3. 

Tell `cut` what is the delimiter (separator):
```
printf "name,age,city\nJohn,25,London\n" | cut -d, -f 1,3
â†’
name,city
John,London
```


### ðŸ’» Exercise --  how many unique fruits?

- Create the input data file: `echo -e "apple\nbanana\napple\ncarrot\napple" > fruits.txt`

how would you see the contents of the file? (`cat`)

Now sort the file, remove duplicate lines, and count the lines. Was it so hard?

answer: `sort fruits.txt | uniq | wc -l`

To understand how it works, run it in steps:
```
sort fruits.txt
sort fruits.txt | uniq
sort fruits.txt | uniq | wc -l
```

# Edit with a *real* editor

In almost all linux distros you will find the `vim` and `nano` editors.
`vim` uses technology which was state of the art in 1982, and does not support moving cursor. Let's leave it alone.

`nano` is a full screen editor, with arrow keys to move the cursor but no mouse support. Instructions how to use it are at the bottom of the screen, so no need to remember them by heart.

# ðŸ’» Exercise -- summary
Now that you have a few simple tools, combine them to get a real job done!

Your server created a `web_access.log` file. You need to answer the following:

- how many times`index.html` was accessed?
- the list of IP that accessed the site (obviously each IP appears once)
- the IP that access the site the most
- get only the lines that used HTTP GET

The file (more simple than a real log file) is [here](../assets/06/web_access.log)

